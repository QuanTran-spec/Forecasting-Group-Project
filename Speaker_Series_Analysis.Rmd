---
title: "Speaker Series"
author: "Juan Heslop"
date: "12/7/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(tidyverse)
library(forecast)
library(tsibble)
library(hts)
library(lubridate)
library(gridExtra)
theme_set(theme_bw())
setwd('/Users/JuanHeslop/Desktop/IE/Forecasting & Time Series Analysis/Speaker Series')
source("./functions.R")
```

Preprocess the data: Fix, dates, check data types, etc. 

```{r dates}
data = read.csv("./Data/superstore.csv")
data = preprocess(data)
```

No missing values: 

```{r}
sum(apply(is.na(data), 2, sum))
```

## Exploratody Data Analysis

Make dataframe that contains Price of each Product (might be useful then to consider which variables to drop) and also the mean profit: 

```{r}
prices = get_products(data)
```

Products to be discontinued: 

```{r}
worst = prices[prices$Total_Profit < -1000, ]
```

Understanding the variables: 

- *Sales:* Total paid by customer (considers discounts as well). 
- *Profit:* Sales - Cost of Good 

We have many categorical variables that describe Sales and Profit. In order to aggregate into months/weeks, create a function that can also take a filters

Below, dataframe that stores working population per state and per region (2016 through 2019). 

```{r function}
population = read.csv('./Data/population.csv')
```


Monthly:

```{r}
data_m = aggr(data, 'Month')
autoplot(data_m)
```

*Trend*: There is now a more clear picture of the increasing trend. 

*Seasonality* There does appear to be a sort of seasonal pattern for the monthly data

```{r}
grid.arrange(ggseasonplot(data_m[, 1]), ggseasonplot(data_m[, 2]), ncol = 1)
```

The fact that each year the average sales are increasing shoes the increasing trend, and the fact that we face a non-stationary series. 
There appear to be seasonal troughs in February, peak in march, a trough in august, peak in september, trough in october, peak in november, and goes back down again. The seasonal fluctuations are far from being stable. 

Now check graphs for all possible filters: 

```{r}

filtr = c('Ship.Mode', 'Segment', 'State', 'Region', 'Category', 'Sub.Category')

plot_filtr = function(data, by, filtr){
  ag = aggr(data, by, filtr)
  print(autoplot(ag[, 1:(ncol(ag)/2)]) + labs(title = 'Sales'))
  print(autoplot(ag[, ((ncol(ag)/2) + 1):ncol(ag)]) + labs(title = 'Profit'))
}

# SALES
plot_filtr(data, 'Month', 'Segment')
plot_filtr(data, 'Month', 'State')
plot_filtr(data, 'Month', 'Region')
plot_filtr(data, 'Month', 'Category')
plot_filtr(data, 'Month', 'Sub.Category')
```

# Normalize State And Regions by population: 

```{r}
aggr_scale = function(data, pop, by, filtr){

  if (by == 'Month'){
    region_ts = aggr(data, by, filtr)
    columns = colnames(region_ts)
    for (i in 1:ncol(region_ts)){
      region = substr(columns[i], 3, nchar(columns[i]))
      region_ts[1:12, i] = region_ts[1:12, i]/pop[pop$Location == region, 2]
      region_ts[13:24, i] = region_ts[13:24, i]/pop[pop$Location == region, 3]
      region_ts[25:36, i] = region_ts[25:36, i]/pop[pop$Location == region, 4]
      region_ts[37:48, i] = region_ts[37:48, i]/pop[pop$Location == region, 5]}
    
  } else {
    region_ts = aggr(data, by, filtr)
    columns = colnames(region_ts)
    for (i in 1:ncol(region_ts)){
      region = substr(columns[i], 3, nchar(columns[i]))
      region_ts[1:52, i] = region_ts[1:52, i]/pop[pop$Location == region, 2]
      region_ts[53:104, i] = region_ts[53:104, i]/pop[pop$Location == region, 3]
      region_ts[105:156, i] = region_ts[105:156, i]/pop[pop$Location == region, 4]
      region_ts[157:208, i] = region_ts[157:208, i]/pop[pop$Location == region, 5]}
  }
  return(region_ts)
}

# Per Region

regions_scale = aggr_scale(data, population, 'Month', 'Region')
autoplot(regions_scale[, 1:(ncol(regions_scale)/2)]) + 
  labs(title = 'Sales per Capita', y = 'Sales')
autoplot(regions_scale[, (ncol(regions_scale)/2 + 1):ncol(regions_scale)]) + 
  labs(title = 'Profits per Capita', y = 'Profit')

# Per State

regions_scale = aggr_scale(data, population, 'Month', 'State')
autoplot(regions_scale[, 1:(ncol(regions_scale)/2)]) + 
  labs(title = 'Sales per Capita', y = 'Sales')
autoplot(regions_scale[, (ncol(regions_scale)/2 + 1):ncol(regions_scale)]) + 
  labs(title = 'Profits per Capita', y = 'Profit')
unique(data$Segment)

state = aggr(data, 'Month', c('State'))
state_profit = state[, (ncol(state)/2 + 1):ncol(state)]
```

# Check best Places: 

```{r}
regions_scale = aggr_scale(data, population, 'Month', 'Region')
autoplot(regions_scale[, 1:(ncol(regions_scale)/2)]) + 
  labs(title = 'Sales per Capita', y = 'Sales')
autoplot(regions_scale[, (ncol(regions_scale)/2 + 1):ncol(regions_scale)]) + 
  labs(title = 'Profits per Capita', y = 'Profit')
```


# Forecasting: 

```{r}
data_r = aggr(data, 'Month', 'Region')[, seq(1, 7, 2)]

h = 6
train = ts(data_r[1:(nrow(data_r) - h), ], start = c(2015, 1), frequency = 12)
test = ts(data_r[(nrow(data_r) - h):nrow(data_r), ], start = c(2018, 7), frequency = 12)
test.Total = apply(test, 1, sum)
test = cbind(Total, test)
```

```{r}
ht = hts(train)

f1 = forecast(ht, method = 'bu', fmethod = 'ets', h = 7)
fcst = aggts(f1, levels = 0:1)

autoplot(fcst[, 1]) + autolayer(test[, 1])
autoplot(fcst[, 2]) + autolayer(test[, 2])
autoplot(fcst[, 3]) + autolayer(test[, 3])
autoplot(fcst[, 4]) + autolayer(test[, 4])
autoplot(fcst[, 5]) + autolayer(test[, 5])

sqrt(apply((fcst - test)^2, 2, sum))/nrow(fcst)
```


```{r}
data_t = aggr(data, 'Month')[, 1]

h = 6
train = subset(data_t, end = length(data_t) - h)
test = subset(data_t, start = length(data_t) - h + 1)

fit_a = auto.arima(train, 
                   stepwise = FALSE)

frcst2 = forecast(fit_a, h = 6)
autoplot(frcst2) + autolayer(test) + autolayer(fcst[, 1])

accuracy(frcst2, test)[2, 2]

```